

<feed xmlns="http://www.w3.org/2005/Atom">
  <id>http://0.0.0.0:4000/</id>
  <title>Chirpy</title>
  <subtitle>A minimal, portfolio, sidebar, bootstrap Jekyll theme with responsive web design and focuses on text presentation.</subtitle>
  <updated>2021-02-18T13:55:10-05:00</updated>
  <author>
    <name>Elsa Riachi</name>
    <uri>http://0.0.0.0:4000/</uri>
  </author>
  <link rel="self" type="application/atom+xml" href="http://0.0.0.0:4000/feed.xml"/>
  <link rel="alternate" type="text/html" hreflang="en"
    href="http://0.0.0.0:4000/"/>
  <generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator>
  <rights> Â© 2021 Elsa Riachi </rights>
  <icon>/assets/img/favicons/favicon.ico</icon>
  <logo>/assets/img/favicons/favicon-96x96.png</logo>


  
  <entry>
    <title>The Structure of Adversarial Perturbations (Part I)</title>
    <link href="http://0.0.0.0:4000/posts/knowledge_distillation_from_adversarial_examples/" rel="alternate" type="text/html" title="The Structure of Adversarial Perturbations (Part I)" />
    <published>2021-02-13T00:00:00-05:00</published>
  
    <updated>2021-02-17T12:36:56-05:00</updated>
  
    <id>http://0.0.0.0:4000/posts/knowledge_distillation_from_adversarial_examples/</id>
    <content src="http://0.0.0.0:4000/posts/knowledge_distillation_from_adversarial_examples/" />
    <author>
      <name>Elsa Riachi</name>
    </author>

  
    
    <category term="Research" />
    
  

  
    <summary>
      





      
Adversarial vulnerability is a fundamental limitation of deep neural networks which remains poorly understood. Recent work suggests that adversarial attacks exploit the fact that non-robust models rely on superficial statistics to form predictions.



$$
\newcommand\testmacro[2]{\mathbf{F\alpha}(#1)^{#2}}
\def\norm#1{\left\|{#1}\right\|} % A norm with 1 argument
\newcommand\zeronorm[1]{\norm{#...
    </summary>
  

  </entry>

</feed>


